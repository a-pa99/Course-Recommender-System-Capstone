{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef55c645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\n"
     ]
    }
   ],
   "source": [
    "#check python version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c41673c",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626fa5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41938310",
   "metadata": {},
   "source": [
    "### Read In Data File and Clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8db21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in udemy_df\n",
    "udemy_df = pd.read_csv('udemy_master_df.csv', usecols = ['Title', 'Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a701b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all null values\n",
    "udemy_df = udemy_df[udemy_df['Summary'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dfd23a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of the udemy_df \n",
    "course_df = udemy_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8000da23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title      0\n",
       "Summary    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to make sure all null values have been removed\n",
    "course_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77544ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all duplicated values\n",
    "course_df  = course_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "042d07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all non-ascii characters from the dataset\n",
    "course_df = course_df[course_df['Summary'].map(lambda x: x.isascii())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae0b53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A contractions dictionary from Wikipedia found on Stack Overflow for expanding contractions: \n",
    "#https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions_dict = { \n",
    "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is / how does\",\n",
    "\"I'd\": \"I had / I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I shall / I will\",\n",
    "\"I'll've\": \"I shall have / I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ae11322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is code to expand contractions in text created by Abhishek Sharma:\n",
    "#https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-text-data/\n",
    "\n",
    "#Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "#Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "# Expanding Contractions in the reviews and titles for course_df; job_df doesn't include any contractions\n",
    "course_df['Summary']= course_df['Summary'].apply(lambda x:expand_contractions(x))\n",
    "course_df['Title']= course_df['Title'].apply(lambda x:expand_contractions(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40292d0c",
   "metadata": {},
   "source": [
    "### Apply Keyword Extractor YAKE and Vectorize It Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71ed094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import yake for keyword extraction, import cosine sim and countvec for word vectors and similarity measuring\n",
    "import yake\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b8b71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify parameters for yake and create the keyword extractor\n",
    "language = 'en'\n",
    "max_ngram_size = 2\n",
    "deduplication_threshold = 0.9\n",
    "numOfKeywords = 35\n",
    "\n",
    "custom_kw_extractor = yake.KeywordExtractor(lan = language, n = max_ngram_size,\n",
    "                                            dedupLim = deduplication_threshold,\n",
    "                                            top = numOfKeywords, features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c82711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to extract keywords\n",
    "extract_keywords = lambda x: [k[0] for k in custom_kw_extractor.extract_keywords(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24f1e7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time takes to extract keywords:  5.27  mins\n"
     ]
    }
   ],
   "source": [
    "#extract keywords\n",
    "start_time = time.time()\n",
    "\n",
    "course_df['keywords'] = course_df['Summary'].apply(extract_keywords)\n",
    "\n",
    "print(\"Time takes to extract keywords: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf29e4c",
   "metadata": {},
   "source": [
    "### Get Similarity Between Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef645afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create word vectors from course_df, \n",
    "count = CountVectorizer(max_df = 0.7,\n",
    "                        max_features = 10000,\n",
    "                        ngram_range = (1,2),\n",
    "                        lowercase = False,\n",
    "                        tokenizer= lambda i:i,\n",
    "                       )\n",
    "count_matrix = count.fit_transform(course_df['keywords'])\n",
    "\n",
    "countvec_df = pd.DataFrame(count_matrix.toarray(), columns= count.get_feature_names())\n",
    "\n",
    "countvec_df.index = course_df['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0b6505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time takes to make cosine_similarity_df:  3.03  mins\n"
     ]
    }
   ],
   "source": [
    "#get similarity between courses, and create a df for recommender use\n",
    "start_time = time.time()\n",
    "\n",
    "cosine_similarity_array = cosine_similarity(countvec_df)\n",
    "\n",
    "cosine_similarity_df = pd.DataFrame(cosine_similarity_array, columns=countvec_df.index, index=countvec_df.index)\n",
    "\n",
    "print(\"Time takes to make cosine_similarity_df: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53bccac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize summary data for cosine similarity comparison against keywords\n",
    "count2 = CountVectorizer(\n",
    "                        ngram_range = (1,2),\n",
    "                        lowercase = False,\n",
    "                       )\n",
    "\n",
    "vectorized_data = count2.fit_transform(course_df['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0992cea3",
   "metadata": {},
   "source": [
    "### Creating Recommender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebef30bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(job_name,num):\n",
    "    #create a vector of the inputted job title using the vector from above.\n",
    "    query_vec = count2.transform([job_name])\n",
    "    \n",
    "    # calculate similarity with vectorized course summary\n",
    "    similarity = cosine_similarity(query_vec, vectorized_data).flatten() \n",
    "    \n",
    "    #create partitions in the data to make prediction faster\n",
    "    indices = np.argpartition(similarity, -1)[-5:]\n",
    "    \n",
    "    #grab the course name that has the best similarity scores for the given job title\n",
    "    course_name = course_df.iloc[indices][::-1]['Title'].values[0]\n",
    "    \n",
    "    #grab all matches to course names in cosine_similarity df\n",
    "    cosine_similarity_series = cosine_similarity_df.loc[course_name]\n",
    "    \n",
    "    #order values in descending order\n",
    "    ordered_similarities = cosine_similarity_series.sort_values(ascending=False)\n",
    "    \n",
    "    #take the top num of values in descending order\n",
    "    course_list = ordered_similarities[1:num+1]\n",
    "    \n",
    "    return course_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d420b4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "HP LoadRunner 12.55                                             0.734847\n",
      "WebServices Performance Testing Using Loadrunner(SOAP &REST)    0.690268\n",
      "Loadrunner 12.50 SAPGUI Protocol scripting -No Access to lab    0.670820\n",
      "Performance Testing using LoadRunner 12.50                      0.593442\n",
      "Pass the Real Estate Salesperson Exam                           0.507093\n",
      "Name: Bitcoin and CryptoCurrency Jump Start Course, dtype: float64\n",
      "Time takes recommender to recommend:  0.0  mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(recommender('Registered Nurse', 5))\n",
    "print(\"Time takes recommender to recommend: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19d6adca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Become an eBay Entrepreneur- Selling Clothes Online           0.447214\n",
      "Freelance Work From Home: Top 5 Freelancing Skills            0.421637\n",
      "Digital Nomad How-to Guide: Remote Work & Travel The World    0.400000\n",
      "How to Become a Medical Transcriptionist                      0.381385\n",
      "Seth Godin's Freelancer Course                                0.365148\n",
      "Name: Work From Home in Translation | Upwork Translation Course, dtype: float64\n",
      "Time takes recommender to recommend:  0.0  mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(recommender('Translator', 5))\n",
    "print(\"Time takes recommender to recommend: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "418cdf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "PG Diploma in Piping Design Engineering    0.554700\n",
      "How to Design Your Dream Kitchen           0.480384\n",
      "Plumbing System Design Basics (MEP)        0.462250\n",
      "The Fundamentals of Project Management     0.461538\n",
      "Electrical Designing Basics (MEP)          0.438529\n",
      "Name: The Complete Software Engineering Course for Beginners, dtype: float64\n",
      "Time takes recommender to recommend:  0.0  mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(recommender('Software Engineer', 5))\n",
    "print(\"Time takes recommender to recommend: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfa7a35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "How to Create a Brilliant Newsletter People Want to Read?       0.500000\n",
      "Leer betere teksten schrijven, ga leukere content schrijven     0.500000\n",
      "How to live stream, step by step with Open Broadcaster (OBS)    0.447214\n",
      "Bubble Milk Tea Basic Business Training                         0.353553\n",
      "Create & Sell Courses Online (Course Creator's Sales Funnel)    0.353553\n",
      "Name: Track Any HTML5 Content with Custom SCORM, dtype: float64\n",
      "Time takes recommender to recommend:  0.0  mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(recommender('Driver', 5))\n",
    "print(\"Time takes recommender to recommend: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7614aae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Find & Sell Products With Amazon FBA | Beginners Tutorial       0.707107\n",
      "Amazon FBA Arbitrage: Make Money Without Private Labeling       0.617213\n",
      "Retail Arbitrage                                                0.547723\n",
      "Updated: Complete fast-track Amazon FBA beginner course 2020    0.544331\n",
      "Amazon FBA Suspension Prevention Course                         0.544331\n",
      "Name: Arbitrage 101: The Amazon Course, dtype: float64\n",
      "Time takes recommender to recommend:  0.0  mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(recommender('Retail Salesperson', 5))\n",
    "print(\"Time takes recommender to recommend: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da99614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Project Management: From Beginner to \"Project Manager\"         0.559017\n",
      "Management Crash Course: Tactical Training for New Managers    0.547723\n",
      "Financial Accounting for Beginners                             0.534522\n",
      "Learn Project Management with Photoshop 2020                   0.534522\n",
      "Executive Strategy & Management                                0.530330\n",
      "Name: Project Management: Getting Started and Beyond, dtype: float64\n",
      "Time takes recommender to recommend:  0.0  mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(recommender('Project Manager', 5))\n",
    "print(\"Time takes recommender to recommend: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64e6cf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Learn DevOps: Infrastructure Automation With Terraform         0.462910\n",
      "Amazon Web Services(AWS) for Beginners                         0.408248\n",
      "Docker from A to Z™: Swarm + Jenkins                           0.408248\n",
      "Kubernetes + Docker Complete Course - 2 in 1 Hands On!         0.365148\n",
      "Terraform indepth(2020) - With 10 Realworld Job Casestudies    0.365148\n",
      "Name: DevOps Tutorial: Complete Beginners Training - 5 in 1 Bundle, dtype: float64\n",
      "Time takes recommender to recommend:  0.0  mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(recommender('DevOps Engineer', 5))\n",
    "print(\"Time takes recommender to recommend: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2acb6be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Microsoft Azure: Storage and Database                           0.612372\n",
      "Implementing a Data Warehouse with SQL Server 2012              0.609272\n",
      "Data Warehousing for beginners.                                 0.522233\n",
      "Pentaho Data Integration(PDI) Fundamentals and DWH Concepts     0.522233\n",
      "Microsoft SQL Server 2012 Certification Training Exam 70-463    0.476290\n",
      "Name: Database Services on Microsoft AZURE, dtype: float64\n",
      "Time takes recommender to recommend:  0.0  mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(recommender('Warehouse Associate', 5))\n",
    "print(\"Time takes recommender to recommend: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44712690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      " Neuroscience Marketing & Persuasion [OUT NOW]            0.377964\n",
      "Complete Project management crash course                  0.377964\n",
      "TikTok Anti Shadowban Class                               0.377964\n",
      "The Data Science & Machine Learning Bootcamp in Python    0.377964\n",
      "Learn Brave                                               0.377964\n",
      "Name: Become Top Banker With Complete Bank Teller Training - 2019, dtype: float64\n",
      "Time takes recommender to recommend:  0.0  mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(recommender('Cashier', 5))\n",
    "print(\"Time takes recommender to recommend: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "293e5440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "How to Measure Customer Service                              0.866025\n",
      "World Class Customer Service                                 0.750000\n",
      "Customer Service Mastery: Delight Every Customer             0.666667\n",
      "Perfect Customer Service Template: Easily Train Your Team    0.666667\n",
      "Start Improving Customer Service                             0.577350\n",
      "Name: Customer Service Basics, dtype: float64\n",
      "Time takes recommender to recommend:  0.0  mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(recommender('Customer Service Representation', 5))\n",
    "print(\"Time takes recommender to recommend: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5f143ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "Data Science Masterclass With R! 4 Projects+8 Case Studies    0.730297\n",
       "Learn Data Science From Scratch                               0.654654\n",
       "Learn Data Science Basics                                     0.589256\n",
       "R programming from Scratch & Practice Case Studies workout    0.583333\n",
       "Hands-on Tableau-10: Data Science Case Studies In Tableau     0.583333\n",
       "Name: Data Science and Machine Learning Masterclass with R, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender('Data Science', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b2cbeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "Sentiment analysis for chatbots - DialogFlow, IBM Watson        0.572078\n",
       "Building Chatbots with Amazon Lex and IBM Watson                0.426401\n",
       "IBM Watson for Artificial Intelligence & Cognitive Computing    0.402015\n",
       "Comprehensive Guide to Artificial Intelligence(AI) for All      0.363636\n",
       "Machine Learning with AWS AI and IBM Watson                     0.334497\n",
       "Name: Building Chatbots with IBM Watson Assistant: End-to-End, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender('Administrative Assistant', 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
