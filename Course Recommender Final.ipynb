{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check python version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "2dab1c271ddb4c9889e3839f66de62bf",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#import all necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In Data File and Clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "a34d739dc5a3472aaacd8b0e4b85789c",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#read in udemy_df\n",
    "udemy_df = pd.read_csv('udemy_master_df.csv', usecols = ['Title', 'Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "b10f58f5e1e144ad8aba0acdbb03368f",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#remove all null values\n",
    "udemy_df = udemy_df[udemy_df['Summary'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "f4631273a50e4b318cd945244bf16f39",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#create a copy of the udemy_df\n",
    "course_df = udemy_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all duplicated values\n",
    "course_df  = course_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all non-ascii characters from the dataset\n",
    "course_df = course_df[course_df['Summary'].map(lambda x: x.isascii())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A contractions dictionary from Wikipedia found on Stack Overflow for expanding contractions: \n",
    "#https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions_dict = { \n",
    "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is / how does\",\n",
    "\"I'd\": \"I had / I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I shall / I will\",\n",
    "\"I'll've\": \"I shall have / I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is code to expand contractions in text created by Abhishek Sharma:\n",
    "#https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-text-data/\n",
    "\n",
    "#Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "#Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "# Expanding Contractions in the reviews and titles for course_df; job_df doesn't include any contractions\n",
    "course_df['Summary']= course_df['Summary'].apply(lambda x:expand_contractions(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Similarity Between Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "c05e17bf2fdb4fe58503f86fdd370874",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time takes to create word vector:  0.03  mins\n"
     ]
    }
   ],
   "source": [
    "#complete keyword extraction and create word vectors from course_df using tfidfvectorizer\n",
    "start_time = time.time()\n",
    "\n",
    "tfidfvec = TfidfVectorizer(\n",
    "            max_df=0.7,   # note: % of docs in collection\n",
    "            max_features = 10000, # only top 10k by freq,\n",
    "            lowercase = True, \n",
    "            min_df=2,  # note: absolute count of documents\n",
    "            stop_words=\"english\",\n",
    "            ngram_range = (1,2), # include 2-word phrases\n",
    "            use_idf=True, # Enable inverse-document-frequency reweighting. If False, idf(t) = 1.\n",
    "            )\n",
    "\n",
    "vectorized_data = tfidfvec.fit_transform(course_df['Summary'])\n",
    "\n",
    "tfidf_df = pd.DataFrame(vectorized_data.toarray(), columns=tfidfvec.get_feature_names())\n",
    "\n",
    "tfidf_df.index = course_df['Title']\n",
    "\n",
    "print(\"Time takes to create word vector: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time takes to make cosine_similarity_df:  3.01  mins\n"
     ]
    }
   ],
   "source": [
    "#get similarity between courses, and create a cosine similarity df for recommender use\n",
    "start_time = time.time()\n",
    "\n",
    "cosine_similarity_array = cosine_similarity(tfidf_df)\n",
    "\n",
    "cosine_similarity_df = pd.DataFrame(cosine_similarity_array, columns=tfidf_df.index,index=tfidf_df.index)\n",
    "\n",
    "print(\"Time takes to make cosine_similarity_df: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize summary data for cosine similarity comparison against keywords\n",
    "tfidfvec3 = TfidfVectorizer(\n",
    "            lowercase = True, \n",
    "            ngram_range = (1,2), # include 2-word phrases\n",
    "            )\n",
    "\n",
    "vectorized_data = tfidfvec3.fit_transform(course_df['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Recommender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": "ae40ab74a2334e03bc2e61c502e6fb15",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def recommender(job_name, num):\n",
    "    #create a vector of the inputted job title using the vector from above.\n",
    "    query_vec = tfidfvec3.transform([job_name])\n",
    "    \n",
    "    #calculate similarity with vectorized course summary\n",
    "    similarity = cosine_similarity(query_vec, vectorized_data).flatten() \n",
    "    \n",
    "    #create partitions in the data to make prediction faster\n",
    "    indices = np.argpartition(similarity, -1)[-5:]\n",
    "    \n",
    "    #grab the course name that has the best similarity scores for the given job title\n",
    "    course_name = course_df.iloc[indices][::-1]['Title'].values[0]\n",
    "    \n",
    "    #grab all matches to course names in cosine_similarity df\n",
    "    cosine_similarity_series = cosine_similarity_df.loc[course_name]\n",
    "    \n",
    "    #order values in descending order\n",
    "    ordered_similarities = cosine_similarity_series.sort_values(ascending=False)\n",
    "    \n",
    "    #take the top num of values in descending order\n",
    "    course_list = ordered_similarities[0:num]\n",
    "    \n",
    "    return course_list"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "c81b3bcce5ff4c3f9262cc6fdd43a5d2",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
